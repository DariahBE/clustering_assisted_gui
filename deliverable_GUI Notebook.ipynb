{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80085dd",
   "metadata": {},
   "source": [
    "# Clustering pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99efffe4",
   "metadata": {},
   "source": [
    "This clustering notebook helps to group contextless name attestations together based on how similar the strings are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8082e273",
   "metadata": {},
   "source": [
    "## Prep: launching dependencies:\n",
    "\n",
    "To start the process of clustering we'll need to do some base imports - os and sys are standard modules. To avoid overloading this notebook with large code blocks, different tasks of the pipeline are outsourced to separate files that each take care of a different task. These so called *utility* classes are imported as well and do most of the heavy lifting for you. \n",
    "\n",
    "This clustering pipeline is compatible with CUDA-acceleration (NVIDIA), but will work on CPU-only devices too. The notebook automatically looks for a free GPU to use. If none is found, inference will happen on CPU-only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1769667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base imports - nothing fancy here.\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "#reusable componenent utilities : \n",
    "sys.path.append('utils')\n",
    "import gpu_manager  #hardware interaction \n",
    "import callables as c   # getters/setters for pipeline\n",
    "## multiple 'steps' each have their own layer ==> data excahnge using callables\n",
    "from vectorization_layer import TransformerGUI\n",
    "from dimred_layer import DimensionalityReductionGUI\n",
    "from clustering_layer import Clustermachine\n",
    "from noise_extension_layer import NoiseExtender\n",
    "from dimviz import DimensionVisualizer\n",
    "from cluster_inspector import ClusterInspectorGUI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040d4431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 0 free GPUs: []\n",
      "[WARN] No free GPUs found. CUDA_VISIBLE_DEVICES not set.\n",
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "max_gpus = 1        #(INT): how many GPUS is this notebook allowed to use at most? \n",
    "\n",
    "######### Leave this block of code as is: #########\n",
    "gpu_manager.pick_gpu(1, 'auto', int(max_gpus))\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "devices = gpu_manager.pick_gpu(mode = 'report', verbosity=0)\n",
    "if not bool(devices): \n",
    "    device = 'cpu'\n",
    "else:\n",
    "    device = 'cuda'\n",
    "\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdcb6ac",
   "metadata": {},
   "source": [
    "## Step1: Data embedding:\n",
    "Upload the data you want to cluster using the GUI element as a flat file (.txt, .csv or .tsv). Each entry needs to be written on a new line. Quotes can be included, there are UI-elements in place that help you to clean this up. If your exported file contains a header on the first line, you can leave the option \"Drop first row (header)\" ticked, otherwise you should untick it. \n",
    "\n",
    "Once the uploaded data is parsed by the notebook, you can select an embeddings-algorithm, the tool provides a dropdown with some pre-selected options. One of the options is labeled **Custom**, when you select this option, you can provide a reference to any openly accessible model on [Huggingface.co](https://huggingface.co/) and use it in this notebook. \n",
    "\n",
    "The reference for a model is easily found on Huggingface. Let's assum you want to use one of the KaLM-embedding models such as [KaLM-embedding-multilingual-mini-instruct-v2.5](https://huggingface.co/KaLM-Embedding/KaLM-embedding-multilingual-mini-instruct-v2.5). The reference for this model is found at the top of the screen and has a click-to-copy button right next to it. In this case, the custom value you need to provide is: KaLM-Embedding/KaLM-embedding-multilingual-mini-instruct-v2.5 \n",
    "\n",
    "Once you have chosen an embeddings-model, uploaded your data and chose the necessary pre-processing options on it, you can click 'Get embeddings'. \n",
    "\n",
    "Models that are cached on your system will be used immediately, if a model isn't cached, it'll be downloaded - beware that you'll need enough storage space and that this process may take a while depending on your bandwith. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff85c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d66bd7c543415f82bfb69b96575798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FileUpload(value=(), accept='.csv,.txt,.tsv', description='Upload data'), Checkb…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339114695f1842c5a15a4aef43bd7bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TransformerGUI(\n",
    "    config_path = \"transformerconfig.json\", \n",
    "    device = device, \n",
    "    on_result = c.receive_embeddings\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda7619",
   "metadata": {},
   "source": [
    "## Step2: Dimension reduction\n",
    "Embedding models generate a high dimensional dataset. A dimension can be interpreted as a plane on to where you project your data. A 1D plane would be a single line, with points scattered over that line. A 2D plane would be a flat square, where each point has an x and y coordinate. 3D planes are still quite intuitive, you've essentially got a cube in which each point floats. Anything up from this starts to become more exotic. These embedding algorithms produce easily upwards of hundreds of dimensions, e.g. LaBSE - a BERT based model - produces 768 dimensions. \n",
    "\n",
    "High-dimensional data such as this is difficult and slow to cluster, a way to solve this is by applying dimensionality reduction. However, there's a balance to be found. Reduce your dimensions too far (say to a single dimension) and you'd lose a lot of nuance. Keep your dimensions too high and your clustering algorithm will be slow and ineffective. Choosing the right amount of dimensions depends on your dataset, chosen vectorization model and the clustering algorithm you want to use in the end. Finding the right settings for your dataset will include some trial-and-error. It might be needed for you to revisit this step a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a37261a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07aa7191f758480eb789b651c345c1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Dimensionality reduction method:', layout=Layout(width='initial'), option…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DimensionalityReductionGUI(\n",
    "    c.fetch_vectors,\n",
    "    config_path = \"dimredconfig.json\", \n",
    "    on_result = c.receive_reduced\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe1756",
   "metadata": {},
   "source": [
    "## Step3: multidimensionality exploration\n",
    "\n",
    "Visualize the normalized variance of each dimension to get a grasp on how well the embeddings actually represent clusters. Wen sorting on one of the dimension, you'd like to see 'vertical groups' of data; the larger your input dataset, the more difficult it is to actually see this pattern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa750c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bac8205e9ac44dc87028c51bdf6fe1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='primary', description='Update visualization', icon='refresh…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DimensionVisualizer(\n",
    "    c.get_reduced, \n",
    "    normalize=True\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f4280",
   "metadata": {},
   "source": [
    "## Step4: Clustering\n",
    "With the vectors in a reduced state, use the clustering algorithms to extract the clusters; HDBSCAN is a good start for larger datasets, if your dataset is not too big, you can try OPTICS - it'll typically produce smaller, more granular clusters but it doesn't scale well to larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32a30a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fdd599140e43b98cdd7c6a22c7b10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(Dropdown(description='Clustering:', options=(('HDBSCAN (density-based)', 'HDBSCAN…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Clustermachine(\n",
    "    c.get_reduced, \n",
    "    config_path = \"clusterconfig.json\",\n",
    "    on_result = c.receive_vectorlabels, \n",
    "    stringgetter = c.get_input_list\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc78035",
   "metadata": {},
   "source": [
    "## Step5: noise reduction: \n",
    "This step does not produce new clusters, but it will extend existing clusters with noise. There are two methods provided: \n",
    "1) Nearest neighbor (slow): this method will iterate over the reduced-dimensions vector embeddings, pick the noise-point that lives closest to a non-noise point and assign it to that cluster. It'll repeat this process untill all noise has been assigned to a cluster.\n",
    "2) Nearest neighbor (fast): Will group all noise-points and assign each noise-point to the cluster it lives closest to in a single pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3307133a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00682fc80322456d80078ea20f5ac0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Extension method:', options=(('Nearest neighbor (slow, precise)', 'neares…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NoiseExtender(\n",
    "    c.get_reduced, \n",
    "    c.get_cluster_labels, \n",
    "    \"noise_extension_methods.json\", \n",
    "    c.receive_denoised_results\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6bbca",
   "metadata": {},
   "source": [
    "## Step6: Inspect clustering output\n",
    "You can look for specific mentions from your original dataset and see what other mentions share the same cluster label. Alternatively you can pick random labels and inspect them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67fdea85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95724ffc7f241d4a7a6a12d39264fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Use labels:', options=(('Base labels', 'base'), ('Extended labels', 'exte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ClusterInspectorGUI(\n",
    "    c.get_input_list,\n",
    "    c.get_reduced,\n",
    "    c.get_cluster_labels,\n",
    "    c.get_denoised_labels,\n",
    "    c.get_denoised_sources\n",
    ").display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
